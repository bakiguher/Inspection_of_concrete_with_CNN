{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concrete Crack Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from  PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "import splitfolders\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "input_folder='.\\\\data_concreate\\\\SDNET2018\\\\D\\\\'\n",
    "output_folder='\\\\data_concreate\\\\img\\\\'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "InpShape=64\n",
    "batch_size = 32 \n",
    "epochs = 50\n",
    "TENSORBOARD_LOGS=\"cement_binary-{}\".format(int(time.time())) # log file name for tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arrange the images to train validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 13620 files [00:14, 967.66 files/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split with a ratio.\n",
    "splitfolders.ratio(input_folder, output=output_folder,\n",
    "        seed=42, ratio=(.7, .2, .1), group_prefix=None, move=False) # default values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Train val and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28000 images belonging to 2 classes.\n",
      "Found 8000 images belonging to 2 classes.\n",
      "Found 4000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale = 1./255.\n",
    "                                  )\n",
    "training_set = datagen.flow_from_directory('./'+output_folder + 'train',\n",
    "                                                 target_size = (InpShape,InpShape),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 shuffle=True,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "val_set = datagen.flow_from_directory('./'+output_folder +'val',\n",
    "                                    \n",
    "                                            target_size = (InpShape, InpShape),\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "\n",
    "test_set = datagen.flow_from_directory('./'+output_folder +'test',\n",
    "                                            target_size = (InpShape, InpShape),\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics to Follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "   ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(InpShape,InpShape,3))\n",
    "x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 62, 62, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 64)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,641\n",
      "Trainable params: 24,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.BinaryCrossentropy(), # default from_logits=False\n",
    "              metrics=METRICS)\n",
    "\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=8, verbose=1,mode='auto')\n",
    "learning_rate = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, mode='auto')\n",
    "tensorboard=TensorBoard(log_dir='./logs/{}'.format(TENSORBOARD_LOGS)) ## logs are under logs folder for tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "875/875 [==============================] - 48s 50ms/step - loss: 0.0843 - accuracy: 0.9702 - precision: 0.9858 - recall: 0.9541 - tp: 13358.0000 - fp: 192.0000 - tn: 13808.0000 - fn: 642.0000 - val_loss: 0.0421 - val_accuracy: 0.9856 - val_precision: 0.9919 - val_recall: 0.9793 - val_tp: 3917.0000 - val_fp: 32.0000 - val_tn: 3968.0000 - val_fn: 83.0000 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 34s 39ms/step - loss: 0.0437 - accuracy: 0.9855 - precision: 0.9869 - recall: 0.9841 - tp: 13778.0000 - fp: 183.0000 - tn: 13817.0000 - fn: 222.0000 - val_loss: 0.0366 - val_accuracy: 0.9864 - val_precision: 0.9791 - val_recall: 0.9940 - val_tp: 3976.0000 - val_fp: 85.0000 - val_tn: 3915.0000 - val_fn: 24.0000 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 31s 36ms/step - loss: 0.0378 - accuracy: 0.9875 - precision: 0.9878 - recall: 0.9872 - tp: 13821.0000 - fp: 170.0000 - tn: 13830.0000 - fn: 179.0000 - val_loss: 0.0312 - val_accuracy: 0.9889 - val_precision: 0.9858 - val_recall: 0.9920 - val_tp: 3968.0000 - val_fp: 57.0000 - val_tn: 3943.0000 - val_fn: 32.0000 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 32s 36ms/step - loss: 0.0380 - accuracy: 0.9876 - precision: 0.9883 - recall: 0.9869 - tp: 13817.0000 - fp: 164.0000 - tn: 13836.0000 - fn: 183.0000 - val_loss: 0.0326 - val_accuracy: 0.9881 - val_precision: 0.9924 - val_recall: 0.9837 - val_tp: 3935.0000 - val_fp: 30.0000 - val_tn: 3970.0000 - val_fn: 65.0000 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 31s 36ms/step - loss: 0.0322 - accuracy: 0.9889 - precision: 0.9896 - recall: 0.9881 - tp: 13834.0000 - fp: 146.0000 - tn: 13854.0000 - fn: 166.0000 - val_loss: 0.0320 - val_accuracy: 0.9893 - val_precision: 0.9962 - val_recall: 0.9822 - val_tp: 3929.0000 - val_fp: 15.0000 - val_tn: 3985.0000 - val_fn: 71.0000 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "874/875 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9909 - precision: 0.9934 - recall: 0.9884 - tp: 13823.0000 - fp: 92.0000 - tn: 13891.0000 - fn: 162.0000\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "875/875 [==============================] - 32s 36ms/step - loss: 0.0284 - accuracy: 0.9909 - precision: 0.9934 - recall: 0.9884 - tp: 13838.0000 - fp: 92.0000 - tn: 13908.0000 - fn: 162.0000 - val_loss: 0.0406 - val_accuracy: 0.9843 - val_precision: 0.9717 - val_recall: 0.9975 - val_tp: 3990.0000 - val_fp: 116.0000 - val_tn: 3884.0000 - val_fn: 10.0000 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 31s 35ms/step - loss: 0.0198 - accuracy: 0.9932 - precision: 0.9946 - recall: 0.9917 - tp: 13884.0000 - fp: 75.0000 - tn: 13925.0000 - fn: 116.0000 - val_loss: 0.0170 - val_accuracy: 0.9944 - val_precision: 0.9960 - val_recall: 0.9927 - val_tp: 3971.0000 - val_fp: 16.0000 - val_tn: 3984.0000 - val_fn: 29.0000 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 29s 33ms/step - loss: 0.0160 - accuracy: 0.9946 - precision: 0.9963 - recall: 0.9929 - tp: 13901.0000 - fp: 52.0000 - tn: 13948.0000 - fn: 99.0000 - val_loss: 0.0180 - val_accuracy: 0.9942 - val_precision: 0.9925 - val_recall: 0.9960 - val_tp: 3984.0000 - val_fp: 30.0000 - val_tn: 3970.0000 - val_fn: 16.0000 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 29s 34ms/step - loss: 0.0154 - accuracy: 0.9946 - precision: 0.9961 - recall: 0.9931 - tp: 13903.0000 - fp: 55.0000 - tn: 13945.0000 - fn: 97.0000 - val_loss: 0.0158 - val_accuracy: 0.9946 - val_precision: 0.9957 - val_recall: 0.9935 - val_tp: 3974.0000 - val_fp: 17.0000 - val_tn: 3983.0000 - val_fn: 26.0000 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 28s 32ms/step - loss: 0.0147 - accuracy: 0.9951 - precision: 0.9965 - recall: 0.9938 - tp: 13913.0000 - fp: 49.0000 - tn: 13951.0000 - fn: 87.0000 - val_loss: 0.0158 - val_accuracy: 0.9948 - val_precision: 0.9952 - val_recall: 0.9942 - val_tp: 3977.0000 - val_fp: 19.0000 - val_tn: 3981.0000 - val_fn: 23.0000 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 30s 34ms/step - loss: 0.0143 - accuracy: 0.9950 - precision: 0.9963 - recall: 0.9938 - tp: 13913.0000 - fp: 52.0000 - tn: 13948.0000 - fn: 87.0000 - val_loss: 0.0167 - val_accuracy: 0.9946 - val_precision: 0.9950 - val_recall: 0.9942 - val_tp: 3977.0000 - val_fp: 20.0000 - val_tn: 3980.0000 - val_fn: 23.0000 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "874/875 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9951 - precision: 0.9962 - recall: 0.9940 - tp: 13899.0000 - fp: 53.0000 - tn: 13932.0000 - fn: 84.0000\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "875/875 [==============================] - 29s 33ms/step - loss: 0.0140 - accuracy: 0.9951 - precision: 0.9962 - recall: 0.9940 - tp: 13916.0000 - fp: 53.0000 - tn: 13947.0000 - fn: 84.0000 - val_loss: 0.0167 - val_accuracy: 0.9946 - val_precision: 0.9975 - val_recall: 0.9918 - val_tp: 3967.0000 - val_fp: 10.0000 - val_tn: 3990.0000 - val_fn: 33.0000 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 29s 34ms/step - loss: 0.0133 - accuracy: 0.9952 - precision: 0.9967 - recall: 0.9936 - tp: 13911.0000 - fp: 46.0000 - tn: 13954.0000 - fn: 89.0000 - val_loss: 0.0158 - val_accuracy: 0.9951 - val_precision: 0.9950 - val_recall: 0.9952 - val_tp: 3981.0000 - val_fp: 20.0000 - val_tn: 3980.0000 - val_fn: 19.0000 - lr: 1.0000e-05\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 29s 33ms/step - loss: 0.0129 - accuracy: 0.9951 - precision: 0.9963 - recall: 0.9939 - tp: 13915.0000 - fp: 52.0000 - tn: 13948.0000 - fn: 85.0000 - val_loss: 0.0160 - val_accuracy: 0.9949 - val_precision: 0.9943 - val_recall: 0.9955 - val_tp: 3982.0000 - val_fp: 23.0000 - val_tn: 3977.0000 - val_fn: 18.0000 - lr: 1.0000e-05\n",
      "Epoch 15/50\n",
      "874/875 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9952 - precision: 0.9963 - recall: 0.9941 - tp: 13902.0000 - fp: 52.0000 - tn: 13932.0000 - fn: 82.0000\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "875/875 [==============================] - 30s 34ms/step - loss: 0.0129 - accuracy: 0.9952 - precision: 0.9963 - recall: 0.9941 - tp: 13917.0000 - fp: 52.0000 - tn: 13948.0000 - fn: 83.0000 - val_loss: 0.0161 - val_accuracy: 0.9950 - val_precision: 0.9943 - val_recall: 0.9958 - val_tp: 3983.0000 - val_fp: 23.0000 - val_tn: 3977.0000 - val_fn: 17.0000 - lr: 1.0000e-05\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 32s 36ms/step - loss: 0.0127 - accuracy: 0.9952 - precision: 0.9961 - recall: 0.9944 - tp: 13921.0000 - fp: 55.0000 - tn: 13945.0000 - fn: 79.0000 - val_loss: 0.0160 - val_accuracy: 0.9950 - val_precision: 0.9945 - val_recall: 0.9955 - val_tp: 3982.0000 - val_fp: 22.0000 - val_tn: 3978.0000 - val_fn: 18.0000 - lr: 1.0000e-06\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 31s 36ms/step - loss: 0.0127 - accuracy: 0.9952 - precision: 0.9961 - recall: 0.9942 - tp: 13919.0000 - fp: 54.0000 - tn: 13946.0000 - fn: 81.0000 - val_loss: 0.0159 - val_accuracy: 0.9951 - val_precision: 0.9948 - val_recall: 0.9955 - val_tp: 3982.0000 - val_fp: 21.0000 - val_tn: 3979.0000 - val_fn: 18.0000 - lr: 1.0000e-06\n",
      "Epoch 17: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_set, validation_data=val_set, \n",
    "                     epochs = epochs,callbacks = [learning_rate, early_stop, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 4s 28ms/step - loss: 0.0151 - accuracy: 0.9955 - precision: 0.9950 - recall: 0.9960 - tp: 1992.0000 - fp: 10.0000 - tn: 1990.0000 - fn: 8.0000\n"
     ]
    }
   ],
   "source": [
    "#history.model.evaluate(test_datagen)\n",
    "score = model.evaluate(test_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9955022488755622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.995"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP=score[4]\n",
    "FP=score[5]\n",
    "TN=score[6]\n",
    "FN=score[7]\n",
    "ACC=(TP+TN)/(TP+TN+FP+FN)\n",
    "PRS=TP/(TP+FP)\n",
    "REC=TP/(TP+FN)\n",
    "F1=(2*PRS*REC)/(PRS+REC)\n",
    "print(F1)\n",
    "\n",
    "TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"./model/modelbm.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"./model/modelbm.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modelmk_json = \"./model/modelbm.json\"\n",
    "Modelmk_weigths = \"./model/modelbm.h5\"\n",
    "from tensorflow.python.keras.models import model_from_json\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def get_model(modeljson, weights):\n",
    "    '''\n",
    "    Function to load saved model and weights \n",
    "    '''\n",
    "    model_json = open(modeljson, 'r')\n",
    "    loaded_model_json = model_json.read()\n",
    "    model_json.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    model.load_weights(weights)\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_predict(img: image, model, dima: int, dimb: int):\n",
    "    '''\n",
    "    Get the image data and return predictions\n",
    "    '''\n",
    "    img = img.resize((dima, dimb))\n",
    "    x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = x/255\n",
    "    preds = model.predict(x)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = '002-30.jpg'  # Image adress to test\n",
    "im=Image.open(a)\n",
    "modelmk = get_model(Modelmk_json, Modelmk_weigths)\n",
    "\n",
    "# Make predictions\n",
    "predsmk = model_predict(im, modelmk, InpShape, InpShape)[0][0]\n",
    "pred=predsmk *100\n",
    "pred=pred.round(1)\n",
    "pred\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('fpenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78b1e49cd5e32408aa5f511263e1173aa36430829e3ca852ce0af459472a6a2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
