{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from  PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "import splitfolders\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPool2D, AveragePooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from tensorflow.python.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "input_folder='.\\\\data_concreate\\\\D\\\\'\n",
    "output_folder='\\\\data_concreate\\\\images\\\\'\n",
    "InpShape=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Split with a ratio.\n",
    "# # To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "# splitfolders.ratio(input_folder, output=output_folder,\n",
    "#       seed=42, ratio=(.7, .2, .1), group_prefix=None, move=False) # default values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.VGG16(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(InpShape, InpShape, 3), # VGG16 expects min 32 x 32\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      #keras.metrics.CategoricalCrossentropy(name='ccent'),\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "   \n",
    "      \n",
    "      #keras.metrics.AUC(name='auc'),\n",
    "     # keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(InpShape,InpShape,3))\n",
    "x = tf.keras.layers.Conv2D(filters=8, kernel_size=(3,3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2,2))(x)\n",
    "x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2,2))(x)\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2,2))(x)\n",
    "x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2,2))(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(8,activation='relu')(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 62, 62, 8)         224       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 31, 31, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 29, 29, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 14, 14, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 12, 12, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 6, 6, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 4, 4, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 2, 2, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 16)                4112      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,785\n",
      "Trainable params: 28,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NAME=\"cement_binary-{}\".format(int(time.time())) # log file name for tensorboard\n",
    "\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.BinaryCrossentropy(), # default from_logits=False\n",
    "              metrics=METRICS)\n",
    "\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=8, verbose=1,mode='auto')\n",
    "learning_rate = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, mode='auto')\n",
    "tensorboard=TensorBoard(log_dir='./logs/{}'.format(NAME)) ## logs are under logs folder for tensorboard\n",
    "\n",
    "\n",
    "batch_size = 32 \n",
    "epochs = 75\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12442 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255\n",
    "                                  )\n",
    "training_set = train_datagen.flow_from_directory('./'+output_folder + 'train',\n",
    "                                                 target_size = (InpShape,InpShape),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 shuffle=True,\n",
    "                                                 class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3554 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_set = val_datagen.flow_from_directory('./'+output_folder +'val',\n",
    "                                    \n",
    "                                            target_size = (InpShape, InpShape),\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "389/389 [==============================] - 19s 43ms/step - loss: 0.5584 - accuracy: 0.7438 - precision: 0.7307 - recall: 0.8075 - tp: 6003.0000 - fp: 2212.0000 - tn: 4576.0000 - fn: 1431.0000 - val_loss: 0.4848 - val_accuracy: 0.7983 - val_precision: 0.7936 - val_recall: 0.8299 - val_tp: 1542.0000 - val_fp: 401.0000 - val_tn: 1295.0000 - val_fn: 316.0000 - lr: 0.0010\n",
      "Epoch 2/75\n",
      "389/389 [==============================] - 15s 39ms/step - loss: 0.4814 - accuracy: 0.7931 - precision: 0.8073 - recall: 0.7937 - tp: 5162.0000 - fp: 1232.0000 - tn: 4706.0000 - fn: 1342.0000 - val_loss: 0.4379 - val_accuracy: 0.8165 - val_precision: 0.8577 - val_recall: 0.7783 - val_tp: 1446.0000 - val_fp: 240.0000 - val_tn: 1456.0000 - val_fn: 412.0000 - lr: 0.0010\n",
      "Epoch 3/75\n",
      "389/389 [==============================] - 15s 39ms/step - loss: 0.4482 - accuracy: 0.8112 - precision: 0.8293 - recall: 0.8044 - tp: 5232.0000 - fp: 1077.0000 - tn: 4861.0000 - fn: 1272.0000 - val_loss: 0.4059 - val_accuracy: 0.8388 - val_precision: 0.8310 - val_recall: 0.8681 - val_tp: 1613.0000 - val_fp: 328.0000 - val_tn: 1368.0000 - val_fn: 245.0000 - lr: 0.0010\n",
      "Epoch 4/75\n",
      "389/389 [==============================] - 15s 39ms/step - loss: 0.4332 - accuracy: 0.8173 - precision: 0.8363 - recall: 0.8089 - tp: 5261.0000 - fp: 1030.0000 - tn: 4908.0000 - fn: 1243.0000 - val_loss: 0.3937 - val_accuracy: 0.8475 - val_precision: 0.8713 - val_recall: 0.8310 - val_tp: 1544.0000 - val_fp: 228.0000 - val_tn: 1468.0000 - val_fn: 314.0000 - lr: 0.0010\n",
      "Epoch 5/75\n",
      "389/389 [==============================] - 15s 38ms/step - loss: 0.4111 - accuracy: 0.8290 - precision: 0.8479 - recall: 0.8201 - tp: 5334.0000 - fp: 957.0000 - tn: 4981.0000 - fn: 1170.0000 - val_loss: 0.3844 - val_accuracy: 0.8495 - val_precision: 0.8513 - val_recall: 0.8628 - val_tp: 1603.0000 - val_fp: 280.0000 - val_tn: 1416.0000 - val_fn: 255.0000 - lr: 0.0010\n",
      "Epoch 6/75\n",
      "389/389 [==============================] - 15s 39ms/step - loss: 0.4020 - accuracy: 0.8307 - precision: 0.8478 - recall: 0.8241 - tp: 5360.0000 - fp: 962.0000 - tn: 4976.0000 - fn: 1144.0000 - val_loss: 0.3780 - val_accuracy: 0.8540 - val_precision: 0.8904 - val_recall: 0.8219 - val_tp: 1527.0000 - val_fp: 188.0000 - val_tn: 1508.0000 - val_fn: 331.0000 - lr: 0.0010\n",
      "Epoch 7/75\n",
      "389/389 [==============================] - 15s 39ms/step - loss: 0.3873 - accuracy: 0.8385 - precision: 0.8567 - recall: 0.8298 - tp: 5397.0000 - fp: 903.0000 - tn: 5035.0000 - fn: 1107.0000 - val_loss: 0.3588 - val_accuracy: 0.8568 - val_precision: 0.9008 - val_recall: 0.8159 - val_tp: 1516.0000 - val_fp: 167.0000 - val_tn: 1529.0000 - val_fn: 342.0000 - lr: 0.0010\n",
      "Epoch 8/75\n",
      "389/389 [==============================] - 15s 39ms/step - loss: 0.3753 - accuracy: 0.8439 - precision: 0.8591 - recall: 0.8390 - tp: 5457.0000 - fp: 895.0000 - tn: 5043.0000 - fn: 1047.0000 - val_loss: 0.3513 - val_accuracy: 0.8579 - val_precision: 0.8533 - val_recall: 0.8794 - val_tp: 1634.0000 - val_fp: 281.0000 - val_tn: 1415.0000 - val_fn: 224.0000 - lr: 0.0010\n",
      "Epoch 9/75\n",
      "389/389 [==============================] - 15s 38ms/step - loss: 0.3638 - accuracy: 0.8489 - precision: 0.8636 - recall: 0.8442 - tp: 5491.0000 - fp: 867.0000 - tn: 5071.0000 - fn: 1013.0000 - val_loss: 0.3776 - val_accuracy: 0.8421 - val_precision: 0.9091 - val_recall: 0.7756 - val_tp: 1441.0000 - val_fp: 144.0000 - val_tn: 1552.0000 - val_fn: 417.0000 - lr: 0.0010\n",
      "Epoch 10/75\n",
      "389/389 [==============================] - 15s 40ms/step - loss: 0.3479 - accuracy: 0.8544 - precision: 0.8661 - recall: 0.8533 - tp: 5550.0000 - fp: 858.0000 - tn: 5080.0000 - fn: 954.0000 - val_loss: 0.3342 - val_accuracy: 0.8692 - val_precision: 0.8885 - val_recall: 0.8574 - val_tp: 1593.0000 - val_fp: 200.0000 - val_tn: 1496.0000 - val_fn: 265.0000 - lr: 0.0010\n",
      "Epoch 11/75\n",
      "389/389 [==============================] - 15s 39ms/step - loss: 0.3320 - accuracy: 0.8594 - precision: 0.8731 - recall: 0.8555 - tp: 5564.0000 - fp: 809.0000 - tn: 5129.0000 - fn: 940.0000 - val_loss: 0.3828 - val_accuracy: 0.8376 - val_precision: 0.7964 - val_recall: 0.9263 - val_tp: 1721.0000 - val_fp: 440.0000 - val_tn: 1256.0000 - val_fn: 137.0000 - lr: 0.0010\n",
      "Epoch 12/75\n",
      "389/389 [==============================] - 15s 39ms/step - loss: 0.3150 - accuracy: 0.8672 - precision: 0.8773 - recall: 0.8673 - tp: 5641.0000 - fp: 789.0000 - tn: 5149.0000 - fn: 863.0000 - val_loss: 0.3486 - val_accuracy: 0.8596 - val_precision: 0.8508 - val_recall: 0.8870 - val_tp: 1648.0000 - val_fp: 289.0000 - val_tn: 1407.0000 - val_fn: 210.0000 - lr: 0.0010\n",
      "Epoch 13/75\n",
      "388/389 [============================>.] - ETA: 0s - loss: 0.2997 - accuracy: 0.8711 - precision: 0.8784 - recall: 0.8743 - tp: 5670.0000 - fp: 785.0000 - tn: 5140.0000 - fn: 815.0000\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "389/389 [==============================] - 15s 38ms/step - loss: 0.2998 - accuracy: 0.8709 - precision: 0.8785 - recall: 0.8739 - tp: 5684.0000 - fp: 786.0000 - tn: 5152.0000 - fn: 820.0000 - val_loss: 0.3406 - val_accuracy: 0.8588 - val_precision: 0.8970 - val_recall: 0.8245 - val_tp: 1532.0000 - val_fp: 176.0000 - val_tn: 1520.0000 - val_fn: 326.0000 - lr: 0.0010\n",
      "Epoch 14/75\n",
      "389/389 [==============================] - 15s 39ms/step - loss: 0.2485 - accuracy: 0.8983 - precision: 0.9028 - recall: 0.9027 - tp: 5871.0000 - fp: 632.0000 - tn: 5306.0000 - fn: 633.0000 - val_loss: 0.3317 - val_accuracy: 0.8686 - val_precision: 0.8674 - val_recall: 0.8837 - val_tp: 1642.0000 - val_fp: 251.0000 - val_tn: 1445.0000 - val_fn: 216.0000 - lr: 1.0000e-04\n",
      "Epoch 15/75\n",
      "389/389 [==============================] - 16s 40ms/step - loss: 0.2381 - accuracy: 0.9015 - precision: 0.9068 - recall: 0.9047 - tp: 5884.0000 - fp: 605.0000 - tn: 5333.0000 - fn: 620.0000 - val_loss: 0.3265 - val_accuracy: 0.8739 - val_precision: 0.8718 - val_recall: 0.8897 - val_tp: 1653.0000 - val_fp: 243.0000 - val_tn: 1453.0000 - val_fn: 205.0000 - lr: 1.0000e-04\n",
      "Epoch 16/75\n",
      "389/389 [==============================] - 15s 40ms/step - loss: 0.2311 - accuracy: 0.9060 - precision: 0.9082 - recall: 0.9124 - tp: 5934.0000 - fp: 600.0000 - tn: 5338.0000 - fn: 570.0000 - val_loss: 0.3325 - val_accuracy: 0.8723 - val_precision: 0.8695 - val_recall: 0.8891 - val_tp: 1652.0000 - val_fp: 248.0000 - val_tn: 1448.0000 - val_fn: 206.0000 - lr: 1.0000e-04\n",
      "Epoch 17/75\n",
      "389/389 [==============================] - 15s 38ms/step - loss: 0.2249 - accuracy: 0.9107 - precision: 0.9120 - recall: 0.9177 - tp: 5969.0000 - fp: 576.0000 - tn: 5362.0000 - fn: 535.0000 - val_loss: 0.3334 - val_accuracy: 0.8737 - val_precision: 0.8782 - val_recall: 0.8805 - val_tp: 1636.0000 - val_fp: 227.0000 - val_tn: 1469.0000 - val_fn: 222.0000 - lr: 1.0000e-04\n",
      "Epoch 18/75\n",
      "389/389 [==============================] - ETA: 0s - loss: 0.2209 - accuracy: 0.9128 - precision: 0.9147 - recall: 0.9188 - tp: 5976.0000 - fp: 557.0000 - tn: 5381.0000 - fn: 528.0000\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "389/389 [==============================] - 15s 39ms/step - loss: 0.2209 - accuracy: 0.9128 - precision: 0.9147 - recall: 0.9188 - tp: 5976.0000 - fp: 557.0000 - tn: 5381.0000 - fn: 528.0000 - val_loss: 0.3409 - val_accuracy: 0.8647 - val_precision: 0.8892 - val_recall: 0.8466 - val_tp: 1573.0000 - val_fp: 196.0000 - val_tn: 1500.0000 - val_fn: 285.0000 - lr: 1.0000e-04\n",
      "Epoch 19/75\n",
      "389/389 [==============================] - 15s 40ms/step - loss: 0.2122 - accuracy: 0.9158 - precision: 0.9192 - recall: 0.9197 - tp: 5982.0000 - fp: 526.0000 - tn: 5412.0000 - fn: 522.0000 - val_loss: 0.3318 - val_accuracy: 0.8737 - val_precision: 0.8827 - val_recall: 0.8746 - val_tp: 1625.0000 - val_fp: 216.0000 - val_tn: 1480.0000 - val_fn: 233.0000 - lr: 1.0000e-05\n",
      "Epoch 20/75\n",
      "389/389 [==============================] - 16s 42ms/step - loss: 0.2112 - accuracy: 0.9156 - precision: 0.9174 - recall: 0.9216 - tp: 5994.0000 - fp: 540.0000 - tn: 5398.0000 - fn: 510.0000 - val_loss: 0.3329 - val_accuracy: 0.8742 - val_precision: 0.8775 - val_recall: 0.8827 - val_tp: 1640.0000 - val_fp: 229.0000 - val_tn: 1467.0000 - val_fn: 218.0000 - lr: 1.0000e-05\n",
      "Epoch 21/75\n",
      "388/389 [============================>.] - ETA: 0s - loss: 0.2104 - accuracy: 0.9156 - precision: 0.9171 - recall: 0.9219 - tp: 5981.0000 - fp: 541.0000 - tn: 5381.0000 - fn: 507.0000\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "389/389 [==============================] - 15s 38ms/step - loss: 0.2105 - accuracy: 0.9156 - precision: 0.9171 - recall: 0.9219 - tp: 5996.0000 - fp: 542.0000 - tn: 5396.0000 - fn: 508.0000 - val_loss: 0.3328 - val_accuracy: 0.8739 - val_precision: 0.8778 - val_recall: 0.8816 - val_tp: 1638.0000 - val_fp: 228.0000 - val_tn: 1468.0000 - val_fn: 220.0000 - lr: 1.0000e-05\n",
      "Epoch 22/75\n",
      "389/389 [==============================] - 15s 38ms/step - loss: 0.2094 - accuracy: 0.9174 - precision: 0.9179 - recall: 0.9247 - tp: 6014.0000 - fp: 538.0000 - tn: 5400.0000 - fn: 490.0000 - val_loss: 0.3326 - val_accuracy: 0.8742 - val_precision: 0.8787 - val_recall: 0.8811 - val_tp: 1637.0000 - val_fp: 226.0000 - val_tn: 1470.0000 - val_fn: 221.0000 - lr: 1.0000e-06\n",
      "Epoch 23/75\n",
      "389/389 [==============================] - 15s 39ms/step - loss: 0.2093 - accuracy: 0.9171 - precision: 0.9178 - recall: 0.9240 - tp: 6010.0000 - fp: 538.0000 - tn: 5400.0000 - fn: 494.0000 - val_loss: 0.3325 - val_accuracy: 0.8742 - val_precision: 0.8787 - val_recall: 0.8811 - val_tp: 1637.0000 - val_fp: 226.0000 - val_tn: 1470.0000 - val_fn: 221.0000 - lr: 1.0000e-06\n",
      "Epoch 00023: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_set, validation_data=val_set, \n",
    "                     epochs = epochs,callbacks = [learning_rate, early_stop, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1780 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('./'+output_folder +'test',\n",
    "                                            target_size = (InpShape, InpShape),\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 2s 33ms/step - loss: 0.3687 - accuracy: 0.8612 - precision: 0.8576 - recall: 0.8806 - tp: 819.0000 - fp: 136.0000 - tn: 714.0000 - fn: 111.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36867040395736694,\n",
       " 0.8612359762191772,\n",
       " 0.8575916290283203,\n",
       " 0.8806451559066772,\n",
       " 819.0,\n",
       " 136.0,\n",
       " 714.0,\n",
       " 111.0]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#history.model.evaluate(test_datagen)\n",
    "score = model.evaluate(test_set)\n",
    "\n",
    "#score = model.evaluate(generator=test_set)\n",
    "#print('Accuracy:', score[1])\n",
    "score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8689655172413793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP=score[4]\n",
    "FP=score[5]\n",
    "TN=score[6]\n",
    "FN=score[7]\n",
    "ACC=(TP+TN)/(TP+TN+FP+FN)\n",
    "PRS=TP/(TP+FP)\n",
    "REC=TP/(TP+FN)\n",
    "F1=(2*PRS*REC)/(PRS+REC)\n",
    "print(F1)\n",
    "\n",
    "TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model results  \n",
    "56/56 [==============================] - 2s 32ms/step - loss: 0.3017 - accuracy: 0.8685 - precision: 0.8515 - recall: 0.9065 - tp: 843.0000 - fp: 147.0000 - tn: 703.0000 - fn: 87.0000\n",
    "[0.3016987442970276,  \n",
    " 0.8685393333435059,  \n",
    " 0.8515151739120483,  \n",
    " 0.9064516425132751,  \n",
    " 843.0,  \n",
    " 147.0,  \n",
    " 703.0,  \n",
    " 87.0]  \n",
    "\n",
    "inputs = tf.keras.Input(shape=(InpShape,InpShape,3))  \n",
    "x = tf.keras.layers.Conv2D(filters=8, kernel_size=(3,3), activation='relu')(inputs)  \n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2,2))(x)  \n",
    "x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu')(x)  \n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2,2))(x)  \n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)  \n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2,2))(x)  \n",
    "x = tf.keras.layers.Flatten()(x)  \n",
    "x = tf.keras.layers.Dropout(0.2)(x)  \n",
    "x = tf.keras.layers.Dense(16,activation='relu')(x)  \n",
    "\n",
    "x = tf.keras.layers.Dense(8,activation='relu')(x)  \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)  \n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"./model/modelbm.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"./model/modelbm.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modelmk_json = \"./model/modelbm.json\"\n",
    "Modelmk_weigths = \"./model/modelbm.h5\"\n",
    "from tensorflow.python.keras.models import model_from_json\n",
    "\n",
    "def get_model(modeljson, weights):\n",
    "    '''\n",
    "    Function to load saved model and weights \n",
    "    '''\n",
    "    model_json = open(modeljson, 'r')\n",
    "    loaded_model_json = model_json.read()\n",
    "    model_json.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    model.load_weights(weights)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "def model_predict(img: image, model, dima: int, dimb: int):\n",
    "    '''\n",
    "    Get the image data and return predictions\n",
    "    '''\n",
    "    img = img.resize((dima, dimb))\n",
    "    x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = x/255\n",
    "    preds = model.predict(x)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = '021-100.jpg'\n",
    "im=Image.open(a)\n",
    "\n",
    "\n",
    "\n",
    "modelmk = get_model(Modelmk_json, Modelmk_weigths)\n",
    "\n",
    "        # Make predictions\n",
    "predsmk = model_predict(im, modelmk, InpShape, InpShape)[0][0]\n",
    "#predsmk =predsmk *100\n",
    "pred=predsmk *100\n",
    "pred=pred.round(1)\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('fpenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78b1e49cd5e32408aa5f511263e1173aa36430829e3ca852ce0af459472a6a2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
