{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "file='./data/voynich.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5214\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heading</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;f1r.P1.1;H</td>\n",
       "      <td>fachys.ykal.ar.ataiin.shol.shory.cthres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;f1r.P1.2;H</td>\n",
       "      <td>sory.ckhar.or.y.kair.chtaiin.shar.are.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;f1r.P1.3;H</td>\n",
       "      <td>syaiir.sheky.or.ykaiin.shod.cthoary.cth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       heading                                               text\n",
       "0  <f1r.P1.1;H         fachys.ykal.ar.ataiin.shol.shory.cthres...\n",
       "1  <f1r.P1.2;H         sory.ckhar.or.y.kair.chtaiin.shar.are.c...\n",
       "2  <f1r.P1.3;H         syaiir.sheky.or.ykaiin.shod.cthoary.cth..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(file,header=None, sep='\\t',engine='python',names=['image','description'])\n",
    "df = pd.read_csv(file,header=None,sep='>',names=['heading','text'])\n",
    "# df[['image','did']] = df.image.str.split(\"#\",expand=True,)\n",
    "\n",
    "\n",
    "print(len(df))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heading</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f1r.P1.1;H</td>\n",
       "      <td>fachys.ykal.ar.ataiin.shol.shory.cthres.y.kor....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f1r.P1.2;H</td>\n",
       "      <td>sory.ckhar.or.y.kair.chtaiin.shar.are.cthar.ct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1r.P1.3;H</td>\n",
       "      <td>syaiir.sheky.or.ykaiin.shod.cthoary.cthes.dara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1r.P1.4;H</td>\n",
       "      <td>ooiin.oteey.oteos.roloty.cth*ar.daiin.otaiin.o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f1r.P1.5;H</td>\n",
       "      <td>dair.y.chear.cthaiin.cphar.cfhaiin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      heading                                               text\n",
       "0  f1r.P1.1;H  fachys.ykal.ar.ataiin.shol.shory.cthres.y.kor....\n",
       "1  f1r.P1.2;H  sory.ckhar.or.y.kair.chtaiin.shar.are.cthar.ct...\n",
       "2  f1r.P1.3;H  syaiir.sheky.or.ykaiin.shod.cthoary.cthes.dara...\n",
       "3  f1r.P1.4;H  ooiin.oteey.oteos.roloty.cth*ar.daiin.otaiin.o...\n",
       "4  f1r.P1.5;H                 dair.y.chear.cthaiin.cphar.cfhaiin"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['heading'] = df.heading.str.replace('<','')\n",
    "df['text'] = df.text.str.strip()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['page','paragraph','line']] = df.heading.str.split(\".\",expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bakig\\AppData\\Local\\Temp\\ipykernel_4868\\2797887583.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['text']=df['text'].str.replace('.',' ')\n"
     ]
    }
   ],
   "source": [
    "df['page']=df['page'].str.replace('f','')\n",
    "df['text']=df['text'].str.replace('.',' ')\n",
    "df['text']=df['text'].str.replace('=',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heading</th>\n",
       "      <th>text</th>\n",
       "      <th>page</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f1r.P1.1;H</td>\n",
       "      <td>fachys ykal ar ataiin shol shory cthres y kor ...</td>\n",
       "      <td>1r</td>\n",
       "      <td>P1</td>\n",
       "      <td>1;H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f1r.P1.2;H</td>\n",
       "      <td>sory ckhar or y kair chtaiin shar are cthar ct...</td>\n",
       "      <td>1r</td>\n",
       "      <td>P1</td>\n",
       "      <td>2;H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1r.P1.3;H</td>\n",
       "      <td>syaiir sheky or ykaiin shod cthoary cthes dara...</td>\n",
       "      <td>1r</td>\n",
       "      <td>P1</td>\n",
       "      <td>3;H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      heading                                               text page  \\\n",
       "0  f1r.P1.1;H  fachys ykal ar ataiin shol shory cthres y kor ...   1r   \n",
       "1  f1r.P1.2;H  sory ckhar or y kair chtaiin shar are cthar ct...   1r   \n",
       "2  f1r.P1.3;H  syaiir sheky or ykaiin shod cthoary cthes dara...   1r   \n",
       "\n",
       "  paragraph line  \n",
       "0        P1  1;H  \n",
       "1        P1  2;H  \n",
       "2        P1  3;H  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating our own tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    for i in range(0, len(df)):\n",
    "        yield df.iloc[i : ][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tokenizers import Tokenizer, models, normalizers, pre_tokenizers, trainers, processors, decoders\n",
    "tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.normalizer = normalizers.Sequence(\n",
    "    [\n",
    "        normalizers.Replace((r\"[\\p{Other}&&[^\\n\\t\\r]]\"), \"\"),\n",
    "        normalizers.Replace((r\"[\\s]\"), \" \"),\n",
    "        normalizers.Replace((\"!\"), \"\"),\n",
    "        normalizers.Replace((\"%\"), \"\"),\n",
    "        normalizers.Lowercase(),\n",
    "        normalizers.NFD(), normalizers.StripAccents()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.WordPieceTrainer(vocab_size=25000, special_tokens=special_tokens)\n",
    "tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_token_id = tokenizer.token_to_id(\"[CLS]\")\n",
    "sep_token_id = tokenizer.token_to_id(\"[SEP]\")\n",
    "tokenizer.post_processor = processors.TemplateProcessing(\n",
    "    single=f\"[CLS]:0 $A:0 [SEP]:0\",\n",
    "    pair=f\"[CLS]:0 $A:0 [SEP]:0 $B:1 [SEP]:1\",\n",
    "    special_tokens=[(\"[CLS]\", cls_token_id), (\"[SEP]\", sep_token_id)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decoder = decoders.WordPiece(prefix=\"##\",cleanup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save('token_voynich1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "txt_files_dir='./data/tokenfiles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by paragraph\n",
    "datadf=df.groupby(['page','paragraph'])['text'].apply(lambda x: ''.join(x)).reset_index()\n",
    "\n",
    "#group by page\n",
    "#datadf=df.groupby(['page'])['text'].apply(lambda x: ''.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf['size']=datadf['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf.sort_values(by=['page'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>text</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100r</td>\n",
       "      <td>L1</td>\n",
       "      <td>chosarosholsochorcfhyotearchofarysar char-daiindy</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100r</td>\n",
       "      <td>L2</td>\n",
       "      <td>osarochalsainsoitysosamdakocthsofal</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100r</td>\n",
       "      <td>L3</td>\n",
       "      <td>okeeosshockheyorololcheomokolsoteol</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100r</td>\n",
       "      <td>P1</td>\n",
       "      <td>pcheol sheod qocpheeckhy shodol cthdaoto ch qe...</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100r</td>\n",
       "      <td>P2</td>\n",
       "      <td>folshody chol daiin fchodycheol cphol qotees s...</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>99v</td>\n",
       "      <td>P1</td>\n",
       "      <td>sol cheols ockhey qockhy qkoldy s-ok oleees ot...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>99v</td>\n",
       "      <td>P3</td>\n",
       "      <td>qoteeoy chokol qokeeo dy qokeeol olpchey doiir...</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>9r</td>\n",
       "      <td>T</td>\n",
       "      <td>ytchas oraiin chkar</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>9r</td>\n",
       "      <td>P</td>\n",
       "      <td>tydlo choly cthor orchey s shy odaiin sary-sho...</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>9v</td>\n",
       "      <td>P</td>\n",
       "      <td>fochor oporody opy shor daiin qopchypcho qofol...</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>473 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     page paragraph                                               text  size\n",
       "0    100r        L1  chosarosholsochorcfhyotearchofarysar char-daiindy    49\n",
       "1    100r        L2                osarochalsainsoitysosamdakocthsofal    35\n",
       "2    100r        L3                okeeosshockheyorololcheomokolsoteol    35\n",
       "3    100r        P1  pcheol sheod qocpheeckhy shodol cthdaoto ch qe...   238\n",
       "4    100r        P2  folshody chol daiin fchodycheol cphol qotees s...   360\n",
       "..    ...       ...                                                ...   ...\n",
       "467   99v        P1  sol cheols ockhey qockhy qkoldy s-ok oleees ot...   200\n",
       "469   99v        P3  qoteeoy chokol qokeeo dy qokeeol olpchey doiir...   486\n",
       "471    9r         T                                ytchas oraiin chkar    19\n",
       "470    9r         P  tydlo choly cthor orchey s shy odaiin sary-sho...   465\n",
       "472    9v         P  fochor oporody opy shor daiin qopchypcho qofol...   475\n",
       "\n",
       "[473 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=datadf['text']\n",
    "datadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store values in a dataframe column (Series object) to files, one file per record\n",
    "def column_to_files(column, prefix, txt_files_dir):\n",
    "    # The prefix is a unique ID to avoid to overwrite a text file\n",
    "    i=prefix\n",
    "    #For every value in the df, with just one column\n",
    "    for row in column.to_list():\n",
    "      # Create the filename using the prefix ID\n",
    "      file_name = os.path.join(txt_files_dir, str(i)+'.txt')\n",
    "      try:\n",
    "        # Create the file and write the column text to it\n",
    "        f = open(file_name, 'wb')\n",
    "        f.write(row.encode('utf-8'))\n",
    "        f.close()\n",
    "      except Exception as e:  #catch exceptions(for eg. empty rows)\n",
    "        print(row, e) \n",
    "      i+=1\n",
    "    # Return the last ID\n",
    "    return i\n",
    "# Get the training data\n",
    "\n",
    "# Removing the end of line character \\n\n",
    "data = data.replace(\"\\n\",\" \")\n",
    "# Set the ID to 0\n",
    "prefix=0\n",
    "# Create a file for every description value\n",
    "prefix = column_to_files(data, prefix, txt_files_dir)\n",
    "# Print the last ID\n",
    "print(prefix)\n",
    "# Get the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/vocab.json', './data/merges.txt']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer,CharBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "paths = [str(x) for x in Path(\".\").glob(\"./data/tokenfiles/*.txt\")]\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer(lowercase=True)\n",
    "\n",
    "\n",
    "tokenizer.normalizer = normalizers.Sequence(\n",
    "    [\n",
    "        normalizers.Replace((r\"[\\p{Other}&&[^\\n\\t\\r]]\"), \"\"),\n",
    "        normalizers.Replace((r\"[\\s]\"), \" \"),\n",
    "        normalizers.Replace((\"!\"), \"\"),\n",
    "        normalizers.Replace((\"%\"), \"\"),\n",
    "        normalizers.Replace((\"*\"), \"\"),\n",
    "        normalizers.Lowercase(),\n",
    "        normalizers.NFD(), normalizers.StripAccents()]\n",
    ")\n",
    "\n",
    "\n",
    "# Customize training\n",
    "tokenizer.train(files=paths, vocab_size=60000, min_frequency=1,\n",
    "                show_progress=True,\n",
    "                special_tokens=[\n",
    "                                \"<s>\",\n",
    "                                \"<pad>\",\n",
    "                                \"</s>\",\n",
    "                                \"<unk>\",\n",
    "                                \"<mask>\",\n",
    "])\n",
    "#Save the Tokenizer to disk\n",
    "tokenizer.save_model('./data/')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      chosarosholsochorcfhyotearchofarysar char-daii...\n",
       "1      tolchdcholsopchorrolsysol eesosykchochdyykchdy...\n",
       "2      pcheol cheol ol shey qockhol shor yteol sheock...\n",
       "3      sairalyotaldyotalytadokororarotorarotalasoraly...\n",
       "4      dordodorolalydardshotodeeodorpolaiin shocthy q...\n",
       "                             ...                        \n",
       "220    psheoas sheeor qoepsheody odar ocpheo-opar ysa...\n",
       "221    okoramogokarydararokysalooro-ainokorsalolskeea...\n",
       "222    otaramyotoldyotor-chyoldydar-aryotalyolsyarolo...\n",
       "223    tydlo choly cthor orchey s shy odaiin sary-sho...\n",
       "224    fochor oporody opy shor daiin qopchypcho qofol...\n",
       "Name: text, Length: 225, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fachys', 'ykal', 'ataiin', 'shol', 'shory', 'cthres', 'kor', 'sholdy']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True,min_len=3)\n",
    "        final.append(new)\n",
    "    return (final)\n",
    "\n",
    "data_words = gen_words(list(data))\n",
    "\n",
    "print (data_words[0][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
      "ataiin\n"
     ]
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "corpus = []\n",
    "for text in data_words:\n",
    "    new = id2word.doc2bow(text)\n",
    "    corpus.append(new)\n",
    "\n",
    "print (corpus[0][0:20])\n",
    "\n",
    "word = id2word[[0][:1][0]]\n",
    "print (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=7,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           #chunksize=50,\n",
    "                                           passes=50,\n",
    "                                           iterations=150,\n",
    "                                           alpha=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.038*\"qotedy\" + 0.028*\"chckhey\" + 0.022*\"oly\" + 0.018*\"okam\" + 0.018*\"dchedy\" + 0.017*\"olchedy\" + 0.016*\"chcphy\" + 0.015*\"ldy\" + 0.014*\"oaiin\" + 0.014*\"opchdy\"'),\n",
       " (1,\n",
       "  '0.059*\"qokain\" + 0.056*\"daiin\" + 0.053*\"chey\" + 0.040*\"qokaiin\" + 0.028*\"chol\" + 0.023*\"qokey\" + 0.023*\"otain\" + 0.022*\"otal\" + 0.021*\"qol\" + 0.020*\"sheey\"'),\n",
       " (2,\n",
       "  '0.052*\"okeey\" + 0.048*\"okaiin\" + 0.027*\"okar\" + 0.026*\"chckhy\" + 0.025*\"okeedy\" + 0.024*\"okal\" + 0.022*\"qotaiin\" + 0.019*\"qokal\" + 0.019*\"olkeey\" + 0.018*\"lkain\"'),\n",
       " (3,\n",
       "  '0.060*\"ain\" + 0.057*\"otaiin\" + 0.052*\"oteey\" + 0.048*\"raiin\" + 0.044*\"oteedy\" + 0.031*\"cheo\" + 0.029*\"dair\" + 0.021*\"oty\" + 0.018*\"qotchedy\" + 0.018*\"shar\"'),\n",
       " (4,\n",
       "  '0.086*\"chedy\" + 0.061*\"shey\" + 0.061*\"qokeey\" + 0.057*\"qokeedy\" + 0.048*\"shedy\" + 0.025*\"qokedy\" + 0.024*\"otedy\" + 0.022*\"lchedy\" + 0.017*\"qoky\" + 0.017*\"saiin\"'),\n",
       " (5,\n",
       "  '0.083*\"aiin\" + 0.035*\"okain\" + 0.026*\"qokar\" + 0.023*\"dar\" + 0.019*\"chdy\" + 0.017*\"lkeey\" + 0.016*\"qotain\" + 0.014*\"lkaiin\" + 0.014*\"qotar\" + 0.013*\"dal\"'),\n",
       " (6,\n",
       "  '0.091*\"cheey\" + 0.075*\"dain\" + 0.058*\"cheol\" + 0.054*\"otar\" + 0.018*\"orain\" + 0.015*\"qodaiin\" + 0.013*\"sheor\" + 0.012*\"shody\" + 0.012*\"oraiin\" + 0.011*\"shor\"')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq=data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "page                                                   9v\n",
       "text    fochor oporody opy shor daiin qopchypcho qofol...\n",
       "size                                                  475\n",
       "Name: 224, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadf.iloc[224,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctopics=[]\n",
    "datadf\n",
    "k=0\n",
    "for a in data:\n",
    "\n",
    "    bow = id2word.doc2bow(a.split())\n",
    "    t = lda_model.get_document_topics(bow,per_word_topics=False,minimum_probability=0.33)\n",
    "    t.append(datadf.iloc[k,0])\n",
    "    k=k+1\n",
    "    doctopics.append(t)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['100r'],\n",
       " ['100v'],\n",
       " ['101r1'],\n",
       " ['101v2'],\n",
       " ['102r1'],\n",
       " ['102r2'],\n",
       " ['102v1'],\n",
       " ['102v2'],\n",
       " [(4, 0.34753382), '103r'],\n",
       " ['103v'],\n",
       " ['104r'],\n",
       " ['104v'],\n",
       " ['105r'],\n",
       " ['105v'],\n",
       " ['106r'],\n",
       " ['106v'],\n",
       " ['107r'],\n",
       " ['107v'],\n",
       " ['108r'],\n",
       " ['108v'],\n",
       " ['10r'],\n",
       " [(1, 0.34336203), '10v'],\n",
       " ['111r'],\n",
       " ['111v'],\n",
       " ['112r'],\n",
       " ['112v'],\n",
       " ['113r'],\n",
       " ['113v'],\n",
       " ['114r'],\n",
       " ['114v'],\n",
       " ['115r'],\n",
       " ['115v'],\n",
       " ['116r'],\n",
       " ['11r'],\n",
       " ['11v'],\n",
       " ['13r'],\n",
       " ['13v'],\n",
       " ['14r'],\n",
       " ['14v'],\n",
       " ['15r'],\n",
       " ['15v'],\n",
       " ['16r'],\n",
       " [(1, 0.36583865), '16v'],\n",
       " ['17r'],\n",
       " ['17v'],\n",
       " ['18r'],\n",
       " ['18v'],\n",
       " ['19r'],\n",
       " [(1, 0.34915885), '19v'],\n",
       " ['1r'],\n",
       " ['1v'],\n",
       " ['20r'],\n",
       " ['20v'],\n",
       " ['21r'],\n",
       " ['21v'],\n",
       " ['22r'],\n",
       " ['22v'],\n",
       " ['23r'],\n",
       " ['23v'],\n",
       " ['24r'],\n",
       " ['24v'],\n",
       " ['25r'],\n",
       " [(1, 0.33740517), '25v'],\n",
       " ['26r'],\n",
       " ['26v'],\n",
       " ['27r'],\n",
       " ['27v'],\n",
       " ['28r'],\n",
       " [(1, 0.34578797), '28v'],\n",
       " ['29r'],\n",
       " ['29v'],\n",
       " ['2r'],\n",
       " ['2v'],\n",
       " ['30r'],\n",
       " ['30v'],\n",
       " ['31r'],\n",
       " ['31v'],\n",
       " ['32r'],\n",
       " [(1, 0.33555812), '32v'],\n",
       " ['33r'],\n",
       " ['33v'],\n",
       " ['34r'],\n",
       " ['34v'],\n",
       " ['35r'],\n",
       " ['35v'],\n",
       " ['36r'],\n",
       " ['36v'],\n",
       " ['37r'],\n",
       " [(1, 0.3505167), '37v'],\n",
       " ['38r'],\n",
       " ['38v'],\n",
       " ['39r'],\n",
       " ['39v'],\n",
       " ['3r'],\n",
       " ['3v'],\n",
       " ['40r'],\n",
       " ['40v'],\n",
       " ['41r'],\n",
       " ['41v'],\n",
       " ['42r'],\n",
       " ['42v'],\n",
       " ['43r'],\n",
       " ['43v'],\n",
       " ['44r'],\n",
       " ['44v'],\n",
       " ['45r'],\n",
       " ['45v'],\n",
       " ['46r'],\n",
       " ['46v'],\n",
       " ['47r'],\n",
       " ['47v'],\n",
       " ['48r'],\n",
       " ['48v'],\n",
       " ['49r'],\n",
       " [(1, 0.37333706), '49v'],\n",
       " ['4r'],\n",
       " ['4v'],\n",
       " ['50r'],\n",
       " ['50v'],\n",
       " ['51r'],\n",
       " ['51v'],\n",
       " ['52r'],\n",
       " ['52v'],\n",
       " ['53r'],\n",
       " ['53v'],\n",
       " ['54r'],\n",
       " ['54v'],\n",
       " ['55r'],\n",
       " ['55v'],\n",
       " [(1, 0.3353841), '56r'],\n",
       " [(1, 0.3462021), '56v'],\n",
       " ['57r'],\n",
       " ['57v'],\n",
       " ['58r'],\n",
       " ['58v'],\n",
       " [(1, 0.33173972), '5r'],\n",
       " [(1, 0.34476975), '5v'],\n",
       " ['65r'],\n",
       " ['65v'],\n",
       " ['66r'],\n",
       " ['66v'],\n",
       " ['67r1'],\n",
       " ['67r2'],\n",
       " ['67v1'],\n",
       " ['67v2'],\n",
       " ['68r1'],\n",
       " ['68r2'],\n",
       " ['68r3'],\n",
       " ['68v1'],\n",
       " ['68v2'],\n",
       " ['68v3'],\n",
       " ['69r'],\n",
       " ['69v'],\n",
       " ['6r'],\n",
       " ['6v'],\n",
       " ['70r1'],\n",
       " ['70r2'],\n",
       " ['70v1'],\n",
       " ['70v2'],\n",
       " ['71r'],\n",
       " ['71v'],\n",
       " ['72r1'],\n",
       " ['72r2'],\n",
       " ['72r3'],\n",
       " ['72v1'],\n",
       " ['72v2'],\n",
       " ['72v3'],\n",
       " ['73r'],\n",
       " ['73v'],\n",
       " [(4, 0.33360848), '75r'],\n",
       " ['75v'],\n",
       " ['76r'],\n",
       " [(4, 0.3534563), '76v'],\n",
       " ['77r'],\n",
       " ['77v'],\n",
       " ['78r'],\n",
       " ['78v'],\n",
       " ['79r'],\n",
       " ['79v'],\n",
       " ['7r'],\n",
       " ['7v'],\n",
       " ['80r'],\n",
       " ['80v'],\n",
       " ['81r'],\n",
       " ['81v'],\n",
       " ['82r'],\n",
       " ['82v'],\n",
       " [(4, 0.36653274), '83r'],\n",
       " ['83v'],\n",
       " ['84r'],\n",
       " ['84v'],\n",
       " ['85r1'],\n",
       " ['85r2'],\n",
       " ['86v3'],\n",
       " ['86v4'],\n",
       " ['86v5'],\n",
       " ['86v6'],\n",
       " ['87r'],\n",
       " ['87v'],\n",
       " ['88r'],\n",
       " ['88v'],\n",
       " ['89r1'],\n",
       " ['89r2'],\n",
       " ['89v1'],\n",
       " [(1, 0.3376075), '89v2'],\n",
       " ['8r'],\n",
       " ['8v'],\n",
       " ['90r1'],\n",
       " ['90r2'],\n",
       " ['90v1'],\n",
       " ['90v2'],\n",
       " ['93r'],\n",
       " ['93v'],\n",
       " ['94r'],\n",
       " ['94v'],\n",
       " ['95r1'],\n",
       " ['95r2'],\n",
       " ['95v1'],\n",
       " ['95v2'],\n",
       " ['96r'],\n",
       " ['96v'],\n",
       " ['99r'],\n",
       " ['99v'],\n",
       " ['9r'],\n",
       " [(1, 0.34231612), '9v']]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctopics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\_projects\\final_project_challenge\\fpenv\\lib\\site-packages\\pyLDAvis\\_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el486826337511075525881663117\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el486826337511075525881663117_data = {\"mdsDat\": {\"x\": [0.10494340370561517, -0.011086589247711802, -0.3035608446019086, -0.25830472778762315, 0.2317343738526048, 0.23350650013195295, 0.002767883947070655], \"y\": [-0.3433076954914091, 0.33462928324580643, 0.14895253804742128, -0.19060085755443615, 0.15783499699373515, -0.06365989336236301, -0.04384837187875467], \"topics\": [1, 2, 3, 4, 5, 6, 7], \"cluster\": [1, 1, 1, 1, 1, 1, 1], \"Freq\": [24.39701842867915, 20.517052341328558, 19.28527753548758, 15.459125410332925, 8.099081336983375, 7.8444697536189905, 4.39797519356942]}, \"tinfo\": {\"Term\": [\"chedy\", \"aiin\", \"qokain\", \"shey\", \"qokeey\", \"daiin\", \"cheey\", \"qokeedy\", \"chey\", \"shedy\", \"dain\", \"okeey\", \"okaiin\", \"qokaiin\", \"ain\", \"otaiin\", \"cheol\", \"okain\", \"otar\", \"oteey\", \"qokain\", \"daiin\", \"chey\", \"qokaiin\", \"chol\", \"qokey\", \"otain\", \"otal\", \"qol\", \"sheey\", \"rain\", \"chcthy\", \"chor\", \"qoteey\", \"chy\", \"cheor\", \"qoty\", \"lshey\", \"sheody\", \"teey\", \"aiin\", \"okain\", \"qokar\", \"dar\", \"chdy\", \"lkeey\", \"qotain\", \"lkaiin\", \"qotar\", \"dal\", \"chody\", \"chal\", \"kaiin\", \"odaiin\", \"char\", \"qopchedy\", \"qokchy\", \"kain\", \"chl\", \"oiin\", \"chedy\", \"shey\", \"qokeey\", \"qokeedy\", \"shedy\", \"qokedy\", \"otedy\", \"lchedy\", \"qoky\", \"saiin\", \"cheody\", \"qokchedy\", \"air\", \"shckhy\", \"qoteedy\", \"sheedy\", \"sheol\", \"keedy\", \"opchedy\", \"shol\", \"okeey\", \"okaiin\", \"okar\", \"chckhy\", \"okeedy\", \"okal\", \"qotaiin\", \"qokal\", \"olkeey\", \"lkain\", \"okedy\", \"lkeedy\", \"sain\", \"lor\", \"cheedy\", \"lchey\", \"okey\", \"aiiin\", \"lshedy\", \"lkar\", \"ain\", \"otaiin\", \"oteey\", \"raiin\", \"oteedy\", \"cheo\", \"dair\", \"oty\", \"qotchedy\", \"shar\", \"chedar\", \"chear\", \"otol\", \"taiin\", \"tar\", \"qor\", \"cheos\", \"chky\", \"pchedy\", \"chees\", \"cheey\", \"dain\", \"cheol\", \"otar\", \"orain\", \"qodaiin\", \"sheor\", \"shody\", \"oraiin\", \"shor\", \"sor\", \"chkar\", \"qotchey\", \"ram\", \"shky\", \"choty\", \"polaiin\", \"qoteody\", \"dary\", \"okor\", \"qotedy\", \"chckhey\", \"oly\", \"okam\", \"dchedy\", \"olchedy\", \"chcphy\", \"ldy\", \"oaiin\", \"opchdy\", \"oteody\", \"shcthy\", \"qotam\", \"qotchy\", \"ykeedy\", \"cthey\", \"chotar\", \"chain\", \"oteo\", \"chckhhy\"], \"Freq\": [577.0, 590.0, 497.0, 413.0, 407.0, 476.0, 249.0, 383.0, 447.0, 321.0, 204.0, 278.0, 259.0, 337.0, 169.0, 161.0, 158.0, 253.0, 148.0, 148.0, 497.2303289902213, 475.5114995361799, 446.5214154062155, 337.0576775602742, 236.85888368608013, 194.24439165145557, 192.03804827800658, 183.04336109076087, 177.36086907865317, 172.0177159883912, 120.46183863994442, 103.26952571232509, 89.89479542032997, 73.63864111564521, 67.46686605066976, 62.70709255695494, 58.18234696195477, 56.819777304604024, 56.03265362914893, 55.038437707566246, 589.7807765047032, 252.9013863818277, 185.76424723833878, 166.07301007355997, 137.78346325608118, 123.87365895719103, 112.36083078860453, 99.09135570987165, 98.38269855496661, 92.29118704543042, 87.5656823948482, 75.26649457321545, 73.68480626994727, 70.28990454209912, 68.67547175321911, 65.43745766536736, 64.52048574433243, 60.21853184621745, 60.120703955599716, 59.89921161170687, 577.4052021334338, 412.47208740463265, 407.231985703061, 382.48912749107035, 320.81252901502705, 169.36073593927702, 162.58117844041914, 148.3854679043905, 114.05791717697952, 113.4669427357145, 101.84600567401802, 95.28523570756408, 90.81411821825904, 89.05145651656709, 88.15203346353569, 86.28856163629865, 84.37954995506328, 76.07579785330148, 62.813969922238755, 60.76083307112422, 278.04648580605567, 258.49022181034707, 146.96616293331954, 139.8146974761874, 133.1564658998826, 130.37474263365954, 117.93857406357988, 104.4421665590708, 101.66633456672952, 95.57539860005161, 87.6073204256831, 83.27982908844665, 80.3173799748092, 80.23446129684038, 69.53011183578064, 69.36461513173414, 67.43903022129108, 62.03992317837898, 62.054706468536416, 55.534939866800116, 168.94825143296347, 160.92510422203364, 147.93306771717099, 134.8366166246113, 123.72538646133765, 86.1982051950375, 80.71273349442797, 57.87554881739885, 51.52319248185266, 50.34057602256578, 49.541540923149505, 49.39803122942157, 38.1503356302467, 35.96726134010895, 35.116362761216486, 33.56226668305716, 30.566606807974278, 27.07368636903155, 22.351876255547413, 21.727494920462995, 249.06189614432736, 203.58381121071818, 158.34773764126476, 147.8975667498709, 50.23481672003223, 41.50951697948921, 35.33653928601582, 32.92368059628073, 32.919321015910924, 29.082369174459835, 28.8143147194069, 28.923266098211524, 28.576899344352384, 25.451847912070512, 24.36091058757699, 21.529598275104046, 18.280752554525247, 20.07245111548799, 16.006210766878755, 15.542934811271733, 57.995691417492075, 43.20015010648043, 33.79227409775674, 28.26884614007377, 27.10844740845003, 26.46459379908827, 23.998162883140875, 22.956222270256603, 21.82785018562044, 20.916076971096945, 20.27646897322397, 19.798576160189032, 19.156871722403334, 19.109494460663925, 17.24502826086634, 16.358406624575167, 16.00833536347249, 13.93023181778973, 12.521570989988753, 11.118094254765975], \"Total\": [577.0, 590.0, 497.0, 413.0, 407.0, 476.0, 249.0, 383.0, 447.0, 321.0, 204.0, 278.0, 259.0, 337.0, 169.0, 161.0, 158.0, 253.0, 148.0, 148.0, 497.80284937214583, 476.08229289271236, 447.0929303493246, 337.628925068464, 237.42990303697363, 194.81667288982476, 192.61019495679943, 183.614839591319, 177.93330293967836, 172.5890360312842, 121.03802914023143, 103.84169115521907, 90.46584457914798, 74.21088303487969, 68.03877477906417, 63.27780679356055, 58.75346484470028, 57.394342436834336, 56.60394176864693, 55.61521273200878, 590.3576574926564, 253.47908083620507, 186.34180175343386, 166.64933066291655, 138.36020326958106, 124.45342893378645, 112.93861503161685, 99.6691858351445, 98.96020844142387, 92.8667397252799, 88.14267399213145, 75.84524462325314, 74.26172187665063, 70.86772150898413, 69.25256360836548, 66.01593606877677, 65.09890247699421, 60.7954219870174, 60.70097679294608, 60.4782598307401, 577.992009520552, 413.0604726136598, 407.8184933446048, 383.0759248573467, 321.3987093012557, 169.94675901570662, 163.1677097210299, 148.97230911919132, 114.64471182300977, 114.0532907515818, 102.43304603601368, 95.87495916723213, 91.40132195780242, 89.64041174444056, 88.73892734471748, 86.87573811482676, 84.9654260953424, 76.6633982874823, 63.40073819038494, 61.3462868679492, 278.63213779775924, 259.07566768754225, 147.55183796845319, 140.40038025082114, 133.7420920045703, 130.95999806202744, 118.52477276093393, 105.02616366428917, 102.25561584128437, 96.1648133305377, 88.19228171918093, 83.86800511725586, 80.90276480533939, 80.82118506207391, 70.11562598493538, 69.95152831515804, 68.02463618788758, 62.62575360845742, 62.64128710487127, 56.121188825593826, 169.5541984277216, 161.5291495291403, 148.5367071135533, 135.44220504959247, 124.32938604407052, 86.80408513229091, 81.31670156750474, 58.47898821195535, 52.13142742127648, 50.94915010051664, 50.1468971635375, 50.003301958547816, 38.753435323626135, 36.57133188680008, 35.719704507588574, 34.17319322503575, 31.17175444182313, 27.68562296199294, 22.954960480636192, 22.331823880950846, 249.65619377259648, 204.17856677649095, 158.94091306500508, 148.49143372554107, 50.83099056030742, 42.103385631652934, 35.929329913056726, 33.516908775867876, 33.512527026296816, 29.67532710445923, 29.407295405241612, 29.528126000726072, 29.17558157384011, 26.048192853684288, 24.965681294925357, 22.125127378142988, 18.885499693416342, 20.748972196609724, 16.604372015263444, 16.136062086099233, 58.60360570831147, 43.81088822217844, 34.403804150765524, 28.882394567859734, 27.718762135818682, 27.074680767092747, 24.63276893127938, 23.569164664598432, 22.43954558920087, 21.525340267318995, 20.88439601148114, 20.40760685590076, 19.76912674364012, 19.72160841751031, 17.85303260974676, 16.965151691127687, 16.623442813293416, 14.543882475776458, 13.134525283334481, 11.74643629184586], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\"], \"logprob\": [20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.8375, -2.8821, -2.945, -3.2263, -3.5791, -3.7774, -3.7888, -3.8368, -3.8683, -3.8989, -4.2552, -4.4092, -4.5479, -4.7473, -4.8349, -4.908, -4.9829, -5.0066, -5.0206, -5.0385, -2.4936, -3.3403, -3.6488, -3.7609, -3.9476, -4.0541, -4.1516, -4.2773, -4.2845, -4.3484, -4.4009, -4.5523, -4.5735, -4.6207, -4.6439, -4.6922, -4.7063, -4.7753, -4.777, -4.7807, -2.4529, -2.7892, -2.802, -2.8647, -3.0405, -3.6794, -3.7202, -3.8116, -4.0747, -4.0799, -4.1879, -4.2545, -4.3026, -4.3222, -4.3323, -4.3537, -4.3761, -4.4797, -4.6712, -4.7045, -2.9625, -3.0354, -3.6001, -3.6499, -3.6987, -3.7198, -3.8201, -3.9416, -3.9686, -4.0303, -4.1174, -4.1681, -4.2043, -4.2053, -4.3485, -4.3509, -4.379, -4.4625, -4.4622, -4.5732, -2.8142, -2.8629, -2.947, -3.0397, -3.1257, -3.4872, -3.5529, -3.8855, -4.0018, -4.025, -4.041, -4.0439, -4.3023, -4.3612, -4.3851, -4.4304, -4.5239, -4.6452, -4.8369, -4.8652, -2.3942, -2.5958, -2.8471, -2.9153, -3.9952, -4.1859, -4.347, -4.4177, -4.4178, -4.5417, -4.551, -4.5472, -4.5593, -4.6751, -4.7189, -4.8424, -5.006, -4.9125, -5.1389, -5.1683, -3.2728, -3.5674, -3.813, -3.9914, -4.0334, -4.0574, -4.1552, -4.1996, -4.25, -4.2927, -4.3237, -4.3476, -4.3805, -4.383, -4.4857, -4.5385, -4.5601, -4.6991, -4.8058, -4.9246], \"loglift\": [20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.4096, 1.4095, 1.4094, 1.409, 1.4083, 1.4078, 1.4077, 1.4076, 1.4075, 1.4074, 1.4059, 1.4052, 1.4044, 1.403, 1.4023, 1.4016, 1.4009, 1.4006, 1.4006, 1.4003, 1.5829, 1.5816, 1.5808, 1.5804, 1.5797, 1.5792, 1.5788, 1.5781, 1.5781, 1.5777, 1.5773, 1.5763, 1.5761, 1.5757, 1.5755, 1.5751, 1.575, 1.5744, 1.5743, 1.5743, 1.6448, 1.6444, 1.6444, 1.6443, 1.644, 1.6424, 1.6422, 1.6419, 1.6407, 1.6407, 1.6401, 1.6397, 1.6394, 1.6392, 1.6392, 1.639, 1.6389, 1.6381, 1.6365, 1.6362, 1.8649, 1.8647, 1.863, 1.8628, 1.8626, 1.8625, 1.862, 1.8614, 1.8612, 1.8608, 1.8603, 1.8599, 1.8597, 1.8597, 1.8586, 1.8585, 1.8583, 1.8576, 1.8576, 1.8565, 2.5098, 2.5097, 2.5093, 2.5089, 2.5085, 2.5064, 2.506, 2.503, 2.5017, 2.5014, 2.5013, 2.5012, 2.4977, 2.4968, 2.4964, 2.4954, 2.4938, 2.4911, 2.4868, 2.486, 2.543, 2.5424, 2.5416, 2.5414, 2.5336, 2.5312, 2.5287, 2.5275, 2.5275, 2.5252, 2.525, 2.5247, 2.5246, 2.5222, 2.5208, 2.5181, 2.5128, 2.5122, 2.5087, 2.5079, 3.1136, 3.11, 3.1061, 3.1026, 3.1018, 3.1012, 3.0979, 3.0977, 3.0964, 3.0953, 3.0945, 3.0937, 3.0926, 3.0925, 3.0894, 3.0876, 3.0863, 3.0809, 3.0762, 3.069]}, \"token.table\": {\"Topic\": [4, 2, 5, 3, 7, 2, 2, 7, 7, 4, 7, 1, 2, 5, 5, 3, 4, 5, 6, 5, 3, 6, 1, 5, 1, 6, 5, 2, 2, 1, 1, 7, 6, 1, 7, 1, 6, 5, 2, 2, 6, 7, 2, 2, 3, 3, 4, 7, 2, 4, 4, 4, 2, 4, 4, 1, 7, 2, 2, 4, 2, 4, 7, 4, 4, 4, 4, 4, 6, 7, 4, 7, 7, 3, 6, 6, 5, 1, 1, 6, 3, 5, 5, 7, 7, 5, 5, 5, 6, 6, 1, 1, 4, 2, 3, 2, 3, 3, 3, 1, 3, 1, 2, 5, 4, 2, 7, 2, 5, 6, 7, 7, 3, 1, 6, 1, 5, 1, 6, 3, 4, 5, 3, 7, 3, 3, 1, 1, 3, 6, 3, 6, 6, 3, 6, 6, 5, 5, 1, 7], \"Freq\": [0.9900080466517066, 0.9993941681146724, 0.9967314378950172, 0.9956092324574068, 0.9626040380426395, 0.9888556675180925, 0.9963530070916398, 0.9814911713712313, 0.9364542340076351, 0.9971482965351954, 0.9743119040719831, 0.9918944775854918, 0.9973966266233416, 0.9799352858861292, 0.9970706629553081, 0.9982836968258872, 0.9983509241583293, 0.9851412100185022, 0.9973716102826026, 0.9907367823638085, 0.9957723991155996, 0.9940801078409544, 0.9956097278392269, 0.9944900617594791, 0.9997921453393325, 0.9821144761874463, 0.9752354150407173, 0.9884519684858261, 0.9983813289786944, 0.998189347544371, 0.9948506026631917, 0.962496167593222, 0.9943445578412082, 0.9847326060406396, 0.943109751760579, 0.9998271456554026, 0.9991254381921173, 0.996105331851885, 0.9906668444715093, 0.9961036107355873, 0.9636016336716692, 0.9740694720674454, 0.9964756826257631, 0.9869164163843248, 0.9913466099559715, 0.9934732224737592, 0.9863973191426062, 0.9758513009392592, 0.9932859305557953, 0.9982861368433046, 0.9978405869845266, 0.9896503426301567, 0.9963566376782781, 0.9898394825386041, 0.9897625490389804, 0.9931292454954366, 0.9804120102408669, 0.9877557583268127, 0.9920920371704047, 0.9958480559091348, 0.9981099788013092, 0.9926695320996206, 0.969448704615314, 0.9962600400235532, 0.9978197443650093, 0.9944513204971779, 0.9977312818156746, 0.984937277943575, 0.9915678258193833, 0.9603067982098263, 0.9975002268659638, 0.9882628052120063, 0.9755943338969374, 0.9936792819480812, 0.9847064046857869, 0.9836518912744479, 0.996724123598231, 0.9968319695801342, 0.9966514711300706, 0.996690491072708, 0.9989721635407114, 0.997350698378308, 0.9963867038391865, 0.9897578876714204, 0.9576527848353887, 0.9805582313584777, 0.9918092253884546, 0.9583985134088226, 0.9531121914806927, 0.9975444817536191, 0.9981372298942205, 0.9983872141889939, 0.9902294473254374, 0.9981657269049801, 0.9908739552555536, 0.9984807351087192, 0.9944290846074969, 0.9971913534954008, 0.9979929960068947, 0.9958079928287934, 0.9943764364464966, 0.9947547596528641, 0.9846107450825458, 0.9949318981139618, 0.995572463471477, 0.9916891575892436, 0.9610945514380117, 0.9902970248694228, 0.9974789214917442, 0.9939818997816467, 0.9634102654188381, 0.9897001950474549, 0.9916730191943044, 0.9971583273738898, 0.9639031664068592, 0.9871758227928876, 0.9967351015185366, 0.9914239421477294, 0.9597594789177081, 0.9907649244959011, 0.9888413602735143, 0.9813706391834981, 0.9928557697139284, 0.9800267195081278, 0.9987594558107514, 0.9899196469137417, 0.99658705996146, 0.9893303937892634, 0.9886374241887629, 0.9741345047262068, 0.9974326456197815, 0.9613196498217877, 0.9845776715470834, 0.9943552106308471, 0.9772428084084117, 0.986149851605564, 0.9843776024190605, 0.9798513308687737, 0.9889380494690673, 0.9522191759577557], \"Term\": [\"aiiin\", \"aiin\", \"ain\", \"air\", \"chain\", \"chal\", \"char\", \"chckhey\", \"chckhhy\", \"chckhy\", \"chcphy\", \"chcthy\", \"chdy\", \"chear\", \"chedar\", \"chedy\", \"cheedy\", \"chees\", \"cheey\", \"cheo\", \"cheody\", \"cheol\", \"cheor\", \"cheos\", \"chey\", \"chkar\", \"chky\", \"chl\", \"chody\", \"chol\", \"chor\", \"chotar\", \"choty\", \"chy\", \"cthey\", \"daiin\", \"dain\", \"dair\", \"dal\", \"dar\", \"dary\", \"dchedy\", \"kaiin\", \"kain\", \"keedy\", \"lchedy\", \"lchey\", \"ldy\", \"lkaiin\", \"lkain\", \"lkar\", \"lkeedy\", \"lkeey\", \"lor\", \"lshedy\", \"lshey\", \"oaiin\", \"odaiin\", \"oiin\", \"okaiin\", \"okain\", \"okal\", \"okam\", \"okar\", \"okedy\", \"okeedy\", \"okeey\", \"okey\", \"okor\", \"olchedy\", \"olkeey\", \"oly\", \"opchdy\", \"opchedy\", \"oraiin\", \"orain\", \"otaiin\", \"otain\", \"otal\", \"otar\", \"otedy\", \"oteedy\", \"oteey\", \"oteo\", \"oteody\", \"otol\", \"oty\", \"pchedy\", \"polaiin\", \"qodaiin\", \"qokaiin\", \"qokain\", \"qokal\", \"qokar\", \"qokchedy\", \"qokchy\", \"qokedy\", \"qokeedy\", \"qokeey\", \"qokey\", \"qoky\", \"qol\", \"qopchedy\", \"qor\", \"qotaiin\", \"qotain\", \"qotam\", \"qotar\", \"qotchedy\", \"qotchey\", \"qotchy\", \"qotedy\", \"qoteedy\", \"qoteey\", \"qoteody\", \"qoty\", \"raiin\", \"rain\", \"ram\", \"saiin\", \"sain\", \"shar\", \"shckhy\", \"shcthy\", \"shedy\", \"sheedy\", \"sheey\", \"sheody\", \"sheol\", \"sheor\", \"shey\", \"shky\", \"shody\", \"shol\", \"shor\", \"sor\", \"taiin\", \"tar\", \"teey\", \"ykeedy\"]}, \"R\": 20, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 6, 5, 3, 4, 7, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el486826337511075525881663117\", ldavis_el486826337511075525881663117_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el486826337511075525881663117\", ldavis_el486826337511075525881663117_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el486826337511075525881663117\", ldavis_el486826337511075525881663117_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1      0.104943 -0.343308       1        1  24.397018\n",
       "5     -0.011087  0.334629       2        1  20.517052\n",
       "4     -0.303561  0.148953       3        1  19.285278\n",
       "2     -0.258305 -0.190601       4        1  15.459125\n",
       "3      0.231734  0.157835       5        1   8.099081\n",
       "6      0.233507 -0.063660       6        1   7.844470\n",
       "0      0.002768 -0.043848       7        1   4.397975, topic_info=         Term        Freq       Total Category  logprob  loglift\n",
       "1444    chedy  577.000000  577.000000  Default  20.0000  20.0000\n",
       "324      aiin  590.000000  590.000000  Default  19.0000  19.0000\n",
       "1364   qokain  497.000000  497.000000  Default  18.0000  18.0000\n",
       "86       shey  413.000000  413.000000  Default  17.0000  17.0000\n",
       "299    qokeey  407.000000  407.000000  Default  16.0000  16.0000\n",
       "...       ...         ...         ...      ...      ...      ...\n",
       "69      cthey   16.358407   16.965152   Topic7  -4.5385   3.0876\n",
       "2183   chotar   16.008335   16.623443   Topic7  -4.5601   3.0863\n",
       "1413    chain   13.930232   14.543882   Topic7  -4.6991   3.0809\n",
       "2691     oteo   12.521571   13.134525   Topic7  -4.8058   3.0762\n",
       "940   chckhhy   11.118094   11.746436   Topic7  -4.9246   3.0690\n",
       "\n",
       "[160 rows x 6 columns], token_table=      Topic      Freq    Term\n",
       "term                         \n",
       "1842      4  0.990008   aiiin\n",
       "324       2  0.999394    aiin\n",
       "1046      5  0.996731     ain\n",
       "1828      3  0.995609     air\n",
       "1413      7  0.962604   chain\n",
       "...     ...       ...     ...\n",
       "214       6  0.986150     sor\n",
       "472       5  0.984378   taiin\n",
       "495       5  0.979851     tar\n",
       "1168      1  0.988938    teey\n",
       "1451      7  0.952219  ykeedy\n",
       "\n",
       "[140 rows x 3 columns], R=20, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 6, 5, 3, 4, 7, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word,mds=\"mmds\", R=20)\n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('fpenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78b1e49cd5e32408aa5f511263e1173aa36430829e3ca852ce0af459472a6a2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
